{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL DATA CLEANING AND ENLISTING\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pandas.io.html import read_html\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# INCORPORATING DATASET FILE\n",
    "efile = open('./infoboxImg.csv', 'rb')\n",
    "de = pd.read_csv(efile)#, encoding='Windows-1252')\n",
    "\n",
    "hfile = open('./infoboxImgHindi2.csv', 'wb')\n",
    "# dh = pd.read_csv(hfile, encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = [\"Name\",\"Symptoms\",\"Specialty\",\"Usual onset\",\"Duration\",\"Causes\",\"Treatment\",\"Prevention\",\"Prognosis\", \"Frequency\", \"Medication\", \"Diagnostic method\", \"Risk factors\"]\n",
    "#oldattrs = [\"Name\"]\n",
    "# for attr in oldattrs:\n",
    "#   df = df.drop(attr, 1)\n",
    "dh = de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import re\n",
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "GoogleTranslator(source=\"en\", target=\"hi\").translate(de.loc[526, \"Frequency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1123, 1183):\n",
    "  for attribute in attrs:\n",
    "    \n",
    "    value = de.loc[idx, attribute]\n",
    "\n",
    "    if pd.isna(value):\n",
    "      continue\n",
    "      \n",
    "    if value == \"\":\n",
    "      continue\n",
    "\n",
    "    print(idx, attribute)\n",
    "      \n",
    "    translated_value = GoogleTranslator(source=\"en\", target=\"hi\").translate(value)\n",
    "    # print(value)\n",
    "\n",
    "    reg = re.compile(r'[a-zA-Z]')\n",
    "    words = word_tokenize(translated_value)\n",
    "    for word in words:\n",
    "      if reg.match(word):\n",
    "        # print(word)\n",
    "        trans_lit = transliterate(word, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        translated_value = translated_value.replace(word, trans_lit)\n",
    "    \n",
    "    \n",
    "    # print(translated_value)\n",
    "\n",
    "    dh.loc[idx, attribute] = translated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p2 = p3 = 0\n",
    "for idx in range(0, 1183):\n",
    "  for attribute in attrs:\n",
    "    \n",
    "    value = dh.loc[idx, attribute]\n",
    "\n",
    "    if pd.isna(value):\n",
    "      continue\n",
    "      \n",
    "    if value == \"\":\n",
    "      continue\n",
    "\n",
    "    #print(idx, attribute)\n",
    "\n",
    "    if \"â€“\" in value:\n",
    "      print(attribute, \"problem1\")\n",
    "      value = value.replace(\"â€“\", \"-\")\n",
    "      p1+=1\n",
    "    \n",
    "    if \"।\" in value:\n",
    "      print(attribute, \"problem2\")\n",
    "      value = value.replace(\"।\", \"\")\n",
    "      p2+=1\n",
    "    \n",
    "    if \"Â\" in value:\n",
    "      print(attribute, \"problem3\")\n",
    "      value = value.replace(\"Â\", \"\")\n",
    "      p3+=1\n",
    "    \n",
    "    \n",
    "    #print(value)\n",
    "\n",
    "    dh.loc[idx, attribute] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.to_csv(hfile, index=False)\n",
    "#462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.loc[29, \"Usual onset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.loc[526, \"Medication\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = \"  \".join(oldattrs)\n",
    "GoogleTranslator(source=\"en\", target=\"hi\").translate(\"Migraine at Mayo Clinic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhe = {}\n",
    "for attr in attrs:\n",
    "  dhe[attr] = 0\n",
    "dhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxd = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, 1183):\n",
    "  print(idx)\n",
    "  possible = []\n",
    "  for attribute in attrs:\n",
    "    english = 0\n",
    "    value = dh.loc[idx, attribute]\n",
    "\n",
    "    if pd.isna(value):\n",
    "      continue\n",
    "      \n",
    "    if value == \"\":\n",
    "      continue\n",
    "\n",
    "    # print(idx, attribute)\n",
    "      \n",
    "    #translated_value = GoogleTranslator(source=\"en\", target=\"hi\").translate(value)\n",
    "    #print(de.loc[526, \"Medication\"])\n",
    "\n",
    "    reg = re.compile(r'[a-zA-Z]')\n",
    "    words = word_tokenize(value)\n",
    "    for word in words:\n",
    "      if reg.match(word) and (english==0):\n",
    "        #print(word)\n",
    "        dhe[attribute]+=1\n",
    "        possible.append(attribute)\n",
    "        #english = 1\n",
    "        #break\n",
    "  idxd[idx] = possible\n",
    "    \n",
    "    #print(translated_value)\n",
    "\n",
    "    # dh.loc[idx, attribute] = translated_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh[\"ImageURL\"] = de[\"ImageURL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.loc[[874]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
