{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL DATA CLEANING AND ENLISTING\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pandas.io.html import read_html\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# INCORPORATING DATASET FILE\n",
    "file = open('./disease_cleaned.csv', 'rb')\n",
    "df = pd.read_csv(file, encoding='Windows-1252')\n",
    "\n",
    "editfile = open('./infobox.csv', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldattrs = [\"link\",\"Symptoms\",\"Overview\",\"Causes\",\"Risk factors\",\"Diagnosis\",\"Treatment\",\"Remedies\",\"Medication\", \"info-symptoms\", \"info-causes\", \"info-medication\"]\n",
    "for attr in oldattrs:\n",
    "  df = df.drop(attr, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD required names\n",
    "file_name = \"infoindex.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "available = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "file_name = \"infocontent.pkl\"\n",
    "open_file = open(file_name, \"rb\")\n",
    "nocontent = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "len(available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoattr = [\"Specialty\", \"Symptoms\", \"Risk factors\", \"Treatment\", \"Prognosis\", \"Frequency\", \"Causes\", \"Prevention\", \"Duration\", \"Usual onset\", \"Diagnostic method\", \"Medication\"]\n",
    "\n",
    "dictinfo = {}\n",
    "for item in infoattr:\n",
    "  dictinfo[item] = 0\n",
    "\n",
    "dictinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(1179, 1183):\n",
    "  print(row)\n",
    "  if row not in nocontent and row in available:\n",
    "    page = 'https://en.wikipedia.org/wiki/' + df.loc[row, 'Name'].replace(' ', '_')\n",
    "    infoboxes = read_html(page, index_col=0, attrs={\"class\":\"infobox\"})\n",
    "\n",
    "    di = infoboxes[0]\n",
    "    # print(di)\n",
    "\n",
    "    for l in range(len(di)):\n",
    "      if di.iloc[l].name in infoattr:\n",
    "        dictinfo[di.iloc[l].name] += 1\n",
    "        value = di.iloc[l][0]\n",
    "        finalval = []\n",
    "        flag = 0\n",
    "        for char in value:\n",
    "          if char == \"[\":\n",
    "            flag = 1\n",
    "          if char == \"]\":\n",
    "            flag = 0\n",
    "            continue\n",
    "          if flag:\n",
    "            continue\n",
    "          finalval.append(char)\n",
    "        finalval = ''.join(finalval)\n",
    "        # print(finalval)\n",
    "        # print(\"*******\")\n",
    "        df.loc[row, di.iloc[l].name] = finalval\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(editfile, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
